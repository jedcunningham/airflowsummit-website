<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache Airflow – News</title>
    <link>/blog/</link>
    <description>Recent content in News on Apache Airflow</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Blog: Experience in Google Season of Docs 2019 with Apache Airflow</title>
      <link>/blog/experience-in-google-season-of-docs-2019-with-apache-airflow/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/experience-in-google-season-of-docs-2019-with-apache-airflow/</guid>
      <description>
        
        
        &lt;p&gt;I came across &lt;a href=&#34;https://developers.google.com/season-of-docs&#34;&gt;Google Season of Docs&lt;/a&gt; (GSoD) almost by accident, thanks to my extensive HackerNews and Twitter addiction.  I was familiar with the Google Summer of Code but not with this program.
It turns out it was the inaugural phase. I read the details, and the process felt a lot like GSoC except that this was about documentation.&lt;/p&gt;
&lt;h2 id=&#34;about-me&#34;&gt;About Me&lt;/h2&gt;
&lt;p&gt;I have been writing tech articles on medium as well as my blog for the past 1.5 years.  Blogging helps me test my understanding of the concepts as untangling the toughest of ideas in simple sentences requires a considerable time investment.&lt;/p&gt;
&lt;p&gt;Also, I have been working as a Software Developer for the past three years, which involves writing documentation for my projects as well. I completed my B.Tech from  IIT Roorkee. During my stay in college, I applied for GSoC once but didn’t make it through in the final list of selected candidates.&lt;/p&gt;
&lt;p&gt;I saw GSoD as an excellent opportunity to improve my technical writing skills using feedback from the open-source community. I contributed some bug fixes and features to Apache Superset and Apache Druid, but this would be my first contribution as a technical writer.&lt;/p&gt;
&lt;h2 id=&#34;searching-for-the-organization&#34;&gt;Searching for the organization&lt;/h2&gt;
&lt;p&gt;About 40+ organizations were participating in the GSoD. However, there were two which came as the right choice for me in the first instant. The first one was &lt;a href=&#34;https://airflow.apache.org/&#34;&gt;Apache Airflow&lt;/a&gt; because I had already used Airflow extensively and also contributed some custom operators inside the forked version of my previous company.&lt;/p&gt;
&lt;p&gt;The second one was &lt;a href=&#34;http://cassandra.apache.org/&#34;&gt;Apache Cassandra&lt;/a&gt;, on which I also had worked extensively but hadn’t done any code or doc changes.&lt;/p&gt;
&lt;p&gt;Considering the total experience, I decided to go with the Airflow.&lt;/p&gt;
&lt;h2 id=&#34;project-selection&#34;&gt;Project selection&lt;/h2&gt;
&lt;p&gt;After selecting the org, the next step was to choose the project. Again, my previous experience played a role here, and I ended up picking the &lt;strong&gt;How to create a workflow&lt;/strong&gt; . The aim of the project was to write documentation which will help users in creating complex as well as custom DAGs.&lt;br&gt;
The final deliverables were a bit different, though. More on that later.&lt;/p&gt;
&lt;p&gt;After submitting my application, I got involved in my job until one day, I saw a mail from google confirming my selection as a Technical Writer for the project.&lt;/p&gt;
&lt;h2 id=&#34;community-bonding&#34;&gt;Community Bonding&lt;/h2&gt;
&lt;p&gt;Getting selected is just a beginning.  I got the invite to the Airflow slack channel where most of the discussions happened.
My mentor was &lt;a href=&#34;https://github.com/ashb&#34;&gt;Ash-Berlin Taylor&lt;/a&gt; from Apache Airflow. I started talking to my mentor to get a general sense of what deliverables were expected. The deliverables were documented in &lt;a href=&#34;https://cwiki.apache.org/confluence/display/AIRFLOW/Season+of+Docs+2019&#34;&gt;confluence&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A page for how to create a DAG that also includes:
&lt;ul&gt;
&lt;li&gt;Revamping the page related to scheduling a DAG&lt;/li&gt;
&lt;li&gt;Adding tips for specific DAG conditions, such as rerunning a failed task&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A page for developing custom operators that includes:
&lt;ul&gt;
&lt;li&gt;Describing mechanisms that are important when creating an operator, such as template fields, UI color, hooks, connection, etc.&lt;/li&gt;
&lt;li&gt;Describing the responsibility between the operator and the hook&lt;/li&gt;
&lt;li&gt;Considerations for dealing with shared resources (such as connections and hooks)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A page that describes how to define the relationships between tasks. The page should include information about:
&lt;ul&gt;
&lt;li&gt;** &amp;gt;&amp;gt; &amp;lt;&amp;lt; **&lt;/li&gt;
&lt;li&gt;set upstream / set downstream&lt;/li&gt;
&lt;li&gt;helpers method ex. chain&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A page that describes the communication between tasks that also includes:
&lt;ul&gt;
&lt;li&gt;Revamping the page related to macros and XCOM&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My mentor set the expectation early on that the deliverables were sort of like guidelines and not strict rules.
If I wanted to, I could choose to work on something else related to the project also, which was not under deliverables.
After connecting with the mentor, I started engaging with the overall Airflow community. The people in the community were helpful, especially &lt;a href=&#34;https://github.com/mik-laj&#34;&gt;Kamil Bregula&lt;/a&gt;. Kamil helped me in getting started with the guidelines to follow while writing the documentation for Airflow.&lt;/p&gt;
&lt;h2 id=&#34;doc-development&#34;&gt;Doc Development&lt;/h2&gt;
&lt;p&gt;I picked DAG run as my first deliverable. I chose this topic as some parts of it were already documented but needed some additional text.
I splitter the existing Scheduling &amp;amp; Triggers page into two new pages.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Schedulers&lt;/li&gt;
&lt;li&gt;DAG Runs&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Most of the details unrelated to schedulers were moved to DAG runs page, and then missing points such as how to re-run a task or DAG were added.
Once I was satisfied with my version, I asked my mentor and Kamil to review it. For the first version, I shared the text in the Google docs file in which the reviewers added comments.
However, the document started getting messy, and it became difficult to track the changes. The time had come now to raise a proper Pull Request.&lt;/p&gt;
&lt;p&gt;This was the time when I faced my first challenge. The documentation of Apache Airflow is written using RST(reStructuredText) syntax, with which I was entirely unfamiliar. I had mostly worked in Markdown.
I spent the next couple of days understanding the syntax. Fortunately, it was quite easy to get acquainted.
I raised the &lt;a href=&#34;https://github.com/apache/airflow/pull/6295&#34;&gt;Pull Request&lt;/a&gt; and waited for the comments. Finally, after a few days when I saw the comments, they were mostly related to two things - grammar and formatting. There were also comments related to what I had missed or misinterpreted.&lt;/p&gt;
&lt;h3 id=&#34;using-correct-grammar&#34;&gt;Using correct grammar&lt;/h3&gt;
&lt;p&gt;After discussing with Kamil, I decided to follow &lt;a href=&#34;https://developers.google.com/style/&#34;&gt;Google’s Developer Documentation Guidelines&lt;/a&gt;.  These guidelines contain almost everything you’ll need to consider while writing good documentation, such as always to use active voice.
Secondly, I installed the Grammarly app. After writing a doc, I used to put it in Grammarly to check for errors. Then I corrected the errors, made some more changes, and then again pushed it to Grammarly. This was an iterative process until I arrived with a version of the doc, which was grammatically correct but not seemed to have been written by an AI.&lt;/p&gt;
&lt;h3 id=&#34;formatting&#34;&gt;Formatting&lt;/h3&gt;
&lt;p&gt;Formatting involves writing notes and tips, marking the airflow components correctly in the text, and making sure a user who is skimming through the docs doesn’t miss the critical text.
This required a bit of trial and error. I studied the current pattern in Airflow docs and made changes, pushed commits, incorporated new review comments, and then so on.&lt;/p&gt;
&lt;p&gt;In the end, all the reviewers approved the PR, but it was not merged until two months later. This was because we doubted if some more pages, such as &lt;strong&gt;Concepts&lt;/strong&gt;, should also be split up, resulting in a better-structured document. In the end, we decided to delay it until we discussed it with the broader community.&lt;/p&gt;
&lt;p&gt;My &lt;a href=&#34;https://github.com/apache/airflow/pull/6348&#34;&gt;second PR&lt;/a&gt; was a completely new document. It was related to How to create your custom operator. For this, since now I was familiar with most of the syntax, I directly raised the PR without going via Google docs. I received a lot of comments again, but this time they were more related to what I had written rather than how I had written it.
e.g., Describing in detail how to use &lt;strong&gt;template fields&lt;/strong&gt; and clean up my code examples. The fewer grammatical &amp;amp; formatting error comments showed I had made progress.
The PR was accepted within two weeks and gave me a huge confidence boost.&lt;/p&gt;
&lt;p&gt;After my second PR, I was in a bit of a deadlock. My last remaining deliverable was related to &lt;strong&gt;Macros&lt;/strong&gt;, but the scope wasn’t clear. I talked to my mentor, and he told me he didn’t mind if I can go off-track to work on something else while the community figured out what changes were needed.
We discussed a lot of ideas. In the end, I decided to go with the Best Practices guide inspired by my mentors’ &lt;a href=&#34;https://drive.google.com/file/d/1E4zle8-fv5S1rrlcNUzjiEV19OMYvwoY/view?usp=sharing&#34;&gt;talk on Apache Airflow &lt;/a&gt;in a meetup. Having faced challenges while running Airflow in production myself, I was highly motivated to write something like this so that other developers don’t suffer.
The first draft was ready within two weeks. I called it &lt;strong&gt;Running Airflow in Production&lt;/strong&gt;. However, after adding a few more pieces to the document, I realized it was better to call it &lt;strong&gt;Best Practices&lt;/strong&gt; guide, which most of the open-source projects contained.&lt;/p&gt;
&lt;p&gt;People were enthusiastic about this &lt;a href=&#34;https://github.com/apache/airflow/pull/6515&#34;&gt;pull request&lt;/a&gt; since a lot of them faced the challenges described in the doc. I had hit the nail on the head. After some deliberation over the next 1-2 weeks, my PR got accepted.&lt;/p&gt;
&lt;p&gt;I then returned to my first PR and started making some changes related to the new review comments.  After this, I discussed with my mentor about specific elements that were bugging him, such as getting people to understand how the schedule interval works in as few words as possible.
After a lot of trial and error, we arrived at a version with which both of us could make peace.&lt;/p&gt;
&lt;h2 id=&#34;final-evaluation&#34;&gt;Final Evaluation&lt;/h2&gt;
&lt;p&gt;On 12th September, I received mail from Google about the successful completion of the project. This meant my mentor liked my work. The Airflow community also appreciated the contributions.&lt;/p&gt;
&lt;p&gt;My documents were finally published on Airflow website -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://airflow.readthedocs.io/en/latest/dag-run.html&#34;&gt;DAG Runs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://airflow.readthedocs.io/en/latest/scheduler.html&#34;&gt;Scheduler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://airflow.readthedocs.io/en/latest/howto/custom-operator.html&#34;&gt;Creating a custom operator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://airflow.readthedocs.io/en/latest/best-practices.html&#34;&gt;Best Practices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I also started getting invited in the PR reviews of other developers. I am looking forward to more contributions to the project in the coming year.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Blog: Airflow Survey 2019</title>
      <link>/blog/airflow-survey/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/airflow-survey/</guid>
      <description>
        
        
        &lt;h1 id=&#34;apache-airflow-survey-2019&#34;&gt;Apache Airflow Survey 2019&lt;/h1&gt;
&lt;p&gt;Apache Airflow is &lt;a href=&#34;https://www.astronomer.io/blog/why-airflow/&#34;&gt;growing faster than ever&lt;/a&gt;.
Thus, receiving and adjusting to our users’ feedback is a must. We created
&lt;a href=&#34;https://forms.gle/XAzR1pQBZiftvPQM7&#34;&gt;survey&lt;/a&gt; and we got &lt;strong&gt;308&lt;/strong&gt; responses.
Let’s see who Airflow users are, how they play with it, and what they miss.&lt;/p&gt;
&lt;h1 id=&#34;overview-of-the-user&#34;&gt;Overview of the user&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;What best describes your current occupation?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Data Engineer&lt;/td&gt;
&lt;td&gt;194&lt;/td&gt;
&lt;td&gt;62.99%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Developer&lt;/td&gt;
&lt;td&gt;34&lt;/td&gt;
&lt;td&gt;11.04%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Architect&lt;/td&gt;
&lt;td&gt;23&lt;/td&gt;
&lt;td&gt;7.47%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data Scientist&lt;/td&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;6.17%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data Analyst&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;4.22%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DevOps&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;4.22%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;IT Administrator&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0.65%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Machine Learning Engineer&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0.65%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Manager&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0.65%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Operations&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0.65%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Chief Data Officer&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.32%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Engineering Manager&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.32%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Intern&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.32%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Product owner&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.32%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Quant&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.32%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;In your day to day job, what do you use Airflow for?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Data processing (ETL)&lt;/td&gt;
&lt;td&gt;298&lt;/td&gt;
&lt;td&gt;96.75%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Artificial Intelligence and Machine Learning Pipelines&lt;/td&gt;
&lt;td&gt;90&lt;/td&gt;
&lt;td&gt;29.22%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Automating DevOps operations&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;20.78%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;According to the survey, most of the Airflow users are the “data” people. Moreover,
28.57% uses Airflow to both ETL and ML pipelines meaning that those two fields
are somehow connected. Only five respondents use Airflow for DevOps operations only,
That means that other 59 people who use Airflow for DevOps stuff use it also for
ETL / ML  purposes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How many active DAGs do you have in your largest Airflow instance?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0-20&lt;/td&gt;
&lt;td&gt;115&lt;/td&gt;
&lt;td&gt;37.34%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;21-40&lt;/td&gt;
&lt;td&gt;65&lt;/td&gt;
&lt;td&gt;21.10%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;41-60&lt;/td&gt;
&lt;td&gt;44&lt;/td&gt;
&lt;td&gt;14.29%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;61-100&lt;/td&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;101-200&lt;/td&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;201-300&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2.27%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;301-999&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2.60%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000+&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;4.22%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The majority of users do not exceed 100 active DAGs per Airflow instance. However,
as we can see there are users who exceed thousands of DAGs with a maximum number 5000.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What is the maximum number of tasks that you have used in one DAG?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0-10&lt;/td&gt;
&lt;td&gt;61&lt;/td&gt;
&lt;td&gt;19.81%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11-20&lt;/td&gt;
&lt;td&gt;60&lt;/td&gt;
&lt;td&gt;19.48%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;21-30&lt;/td&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;10.06%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;31-40&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;6.82%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;41-50&lt;/td&gt;
&lt;td&gt;26&lt;/td&gt;
&lt;td&gt;8.44%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;51-100&lt;/td&gt;
&lt;td&gt;36&lt;/td&gt;
&lt;td&gt;11.69%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;101-200&lt;/td&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;201-500&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;6.82%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;501+&lt;/td&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;11.54%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The given maximum number of tasks in a single DAG was 10 000 (!). The number of tasks
depends on the purposes of a DAG, so it’s rather hard to say if users have “simple”
or “complicated” workflows.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When onboarding new members to Airflow, what is the biggest problem?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No guide on best practises on developing DAGs&lt;/td&gt;
&lt;td&gt;160&lt;/td&gt;
&lt;td&gt;51.95%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Small number of tutorials on different aspects of using Airflow&lt;/td&gt;
&lt;td&gt;57&lt;/td&gt;
&lt;td&gt;18.51%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Documentation is not clear enough&lt;/td&gt;
&lt;td&gt;42&lt;/td&gt;
&lt;td&gt;13.64%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Small number of blogs regarding Airflow&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;1.95%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Other&lt;/td&gt;
&lt;td&gt;43&lt;/td&gt;
&lt;td&gt;13.96%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This is an important result. Using Airflow is all about writing and scheduling DAGs.
No guide or any other complete resource on best practices for developing Dags is a big
problem. Diving deep in the “other” answers, we can find that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Airflow’s “magic” (scheduler, executors, schedule times) is hard to understand&lt;/li&gt;
&lt;li&gt;DAG testing is not easy to do and to explain&lt;/li&gt;
&lt;li&gt;Airflow UI needs some love.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;How likely are you to recommend Apache Airflow?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Very Likely&lt;/td&gt;
&lt;td&gt;140&lt;/td&gt;
&lt;td&gt;45.45%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Likely&lt;/td&gt;
&lt;td&gt;124&lt;/td&gt;
&lt;td&gt;40.26%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Neutral&lt;/td&gt;
&lt;td&gt;33&lt;/td&gt;
&lt;td&gt;10.71%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Unlikely&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2.60%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Very unlikely&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;0.97%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This means that more than 85% of people who use Airflow like it. It seems Airflow does
its job nicely. However, we have to remember that this survey is likely biased - it’s
more likely that you respond to the survey if you like the tool you use. Should we
focus then on those 11 people who did not like Airflow? It’s a good question.&lt;/p&gt;
&lt;h2 id=&#34;airflow-usage&#34;&gt;Airflow usage&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Which interface(s) of Airflow do you use as part of your current role?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Original Airflow Graphical User Interface&lt;/td&gt;
&lt;td&gt;297&lt;/td&gt;
&lt;td&gt;96.43%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLI&lt;/td&gt;
&lt;td&gt;126&lt;/td&gt;
&lt;td&gt;40.91%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Original Airflow Graphical User Interface, CLI&lt;/td&gt;
&lt;td&gt;117&lt;/td&gt;
&lt;td&gt;37.99%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;API&lt;/td&gt;
&lt;td&gt;60&lt;/td&gt;
&lt;td&gt;19.48%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Original Airflow Graphical User Interface, CLI, API&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;td&gt;10.39%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Custom (own created) Airflow Graphical User Interface&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;8.12%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It’s visible that usage of CLI goes in pair with using Airflow web UI. Our
survey included some UX related questions to allow us to understand how users
use Airflow webserver.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What do you use the Graphical User Interface for?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plot1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What do you use CLI for?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plot2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In Airflow, which UI view(s) are important for you?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plot3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here we see that the majority uses Web UI mostly for monitoring purposes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Monitoring DAGs&lt;/li&gt;
&lt;li&gt;Accessing logs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An interesting result is that many people seem not to use backfilling as
there’s no other way than to do it by CLI.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What executor type do you use?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Celery&lt;/td&gt;
&lt;td&gt;138&lt;/td&gt;
&lt;td&gt;44.81%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Local&lt;/td&gt;
&lt;td&gt;85&lt;/td&gt;
&lt;td&gt;27.60%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kubernetes&lt;/td&gt;
&lt;td&gt;52&lt;/td&gt;
&lt;td&gt;16.88%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sequential&lt;/td&gt;
&lt;td&gt;22&lt;/td&gt;
&lt;td&gt;7.14%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Other&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;3.57&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The other option mostly consisted of information that someone uses a few types or is
migrating from one executor to another. What can be observed is an increase in usage
of Local and Kubernetes executors when compared to results from an earlier &lt;a href=&#34;https://ash.berlintaylor.com/writings/2019/02/airflow-user-survey-2019/&#34;&gt;survey done
by Ash&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do you use Kubernetes-based deployments for Airflow?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No - we do not plan to use Kubernetes near term&lt;/td&gt;
&lt;td&gt;88&lt;/td&gt;
&lt;td&gt;28.57%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Yes - setup on our own via Helm Chart or similar&lt;/td&gt;
&lt;td&gt;65&lt;/td&gt;
&lt;td&gt;21.10%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Not yet - but we use Kubernetes in our organization and we could move&lt;/td&gt;
&lt;td&gt;61&lt;/td&gt;
&lt;td&gt;19.81%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Yes - via managed service in the cloud (Composer / Astronomer etc.)&lt;/td&gt;
&lt;td&gt;45&lt;/td&gt;
&lt;td&gt;14.61%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Not yet - but we plan to deploy Kubernetes in our organization soon&lt;/td&gt;
&lt;td&gt;42&lt;/td&gt;
&lt;td&gt;13.64%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Other&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2.27%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The most interesting thing is that there’s nearly 30% of users who do not use Kubernetes,
and they are not going to move. This means we should keep other deployment options in
mind when working on Airflow 2.0. On the other hand, almost 70% of the users already
use Kubernetes, or it’s a viable option for them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do you combine multiple DAGs?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No, I don&amp;rsquo;t combine multiple DAGs&lt;/td&gt;
&lt;td&gt;127&lt;/td&gt;
&lt;td&gt;41.23%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Yes, through SubDAG&lt;/td&gt;
&lt;td&gt;73&lt;/td&gt;
&lt;td&gt;23.70%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Yes, by triggering another DAG&lt;/td&gt;
&lt;td&gt;72&lt;/td&gt;
&lt;td&gt;23.38%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Other&lt;/td&gt;
&lt;td&gt;36&lt;/td&gt;
&lt;td&gt;11.69%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In the other category, 9 people explicitly mentioned using &lt;code&gt;ExternalTaskSensor&lt;/code&gt;,
and I think it could be treated as running subDAGs by triggering other DAGs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do you use Airflow Plugins? If yes, what do you use it for?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Adding new operators/sensors and hooks&lt;/td&gt;
&lt;td&gt;187&lt;/td&gt;
&lt;td&gt;60.71%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;I don&amp;rsquo;t use Airflow plugins&lt;/td&gt;
&lt;td&gt;109&lt;/td&gt;
&lt;td&gt;35.39%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adding AppBuilder views &amp;amp; menu items&lt;/td&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;10.06%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adding new executor&lt;/td&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;5.84%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adding OperatorExtraLinks&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2.27%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The high percentage - 60%  for “Adding new operators/sensors and hooks” is quite a
surprising result for some of us - especially that you do not actually need to use the
plugin mechanism to add any of those. Those are standard python objects, and you can
simply drop your hooks/operators/sensors code to &lt;code&gt;PYTHONPATH&lt;/code&gt; environment variable and
they will work. It seems that this may be a result of a lack of best practices guide.&lt;/p&gt;
&lt;p&gt;Plugins are more useful for adding views and menu items - yet only 10%.
OperatorExtraLinks are even more useful (though relatively new) feature, so it’s not
entirely surprising they are hardly used.&lt;/p&gt;
&lt;p&gt;It was also kind of surprising that someone at all uses plugins to use their own
executors. We considered removing that option recently - but now we have to rethink
our approach.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What metrics do you use to monitor Airflow?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There were a lot of different responses. Some use Prometheus and other services,
others do not use any monitoring. One of the interesting responses linked to this
solution for &lt;a href=&#34;https://github.com/mastak/airflow_operators_metrics&#34;&gt;airflow_operators_metrics&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;external-services&#34;&gt;External services&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;What external services do you use in your Airflow DAGs?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Amazon Web Services&lt;/td&gt;
&lt;td&gt;160&lt;/td&gt;
&lt;td&gt;51.95%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Internal company systems&lt;/td&gt;
&lt;td&gt;150&lt;/td&gt;
&lt;td&gt;48.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Hadoop / Spark / Flink / Other Apache software&lt;/td&gt;
&lt;td&gt;119&lt;/td&gt;
&lt;td&gt;38.64%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Google Cloud Platform / Google APIs&lt;/td&gt;
&lt;td&gt;112&lt;/td&gt;
&lt;td&gt;36.36%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Microsoft Azure&lt;/td&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;I do not use external services in my Airflow DAGs&lt;/td&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;5.84%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It’s not surprising that Amazon Web Services is leading the way as they are considered the most mature
cloud provider. Internal system and other Apache products on the next two positions are
quite understandable if we take into account that the majority uses Airflow for ETL processes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What external services do you use in your Airflow DAGs? (Mixed providers)&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Google Cloud Platform / Google APIs, Amazon Web Services&lt;/td&gt;
&lt;td&gt;44&lt;/td&gt;
&lt;td&gt;14.29%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Amazon Web Services, Microsoft Azure&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;1.62%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Google Cloud Platform / Google APIs, Microsoft Azure&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;1.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This result is not surprising because companies usually prefer to stick with one cloud
provider.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How do you integrate with external services?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Using Bash / Python operator&lt;/td&gt;
&lt;td&gt;220&lt;/td&gt;
&lt;td&gt;71.43%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Using existing, dedicated operators / hooks&lt;/td&gt;
&lt;td&gt;217&lt;/td&gt;
&lt;td&gt;70.45%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Using own, custom operators / hooks&lt;/td&gt;
&lt;td&gt;216&lt;/td&gt;
&lt;td&gt;70.13%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We had some anecdotal evidence that people use more Python/Bash operators than the
dedicated ones - but it looks like all ways of using Airflow to connect to external
services are equally popular.&lt;/p&gt;
&lt;h2 id=&#34;what-can-be-improved&#34;&gt;What can be improved&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;In your opinion, what could be improved in Airflow?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Scheduler performance&lt;/td&gt;
&lt;td&gt;189&lt;/td&gt;
&lt;td&gt;61.36%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Web UI&lt;/td&gt;
&lt;td&gt;180&lt;/td&gt;
&lt;td&gt;58.44%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Logging, monitoring and alerting&lt;/td&gt;
&lt;td&gt;145&lt;/td&gt;
&lt;td&gt;47.08%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Examples, how-to, onboarding documentation&lt;/td&gt;
&lt;td&gt;143&lt;/td&gt;
&lt;td&gt;46.43%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Technical documentation&lt;/td&gt;
&lt;td&gt;137&lt;/td&gt;
&lt;td&gt;44.48%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reliability&lt;/td&gt;
&lt;td&gt;112&lt;/td&gt;
&lt;td&gt;36.36%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;REST API&lt;/td&gt;
&lt;td&gt;96&lt;/td&gt;
&lt;td&gt;31.17%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Authentication and authorization&lt;/td&gt;
&lt;td&gt;89&lt;/td&gt;
&lt;td&gt;28.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;External integration e.g. AWS, GCP, Apache product&lt;/td&gt;
&lt;td&gt;49&lt;/td&gt;
&lt;td&gt;15.91%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLI&lt;/td&gt;
&lt;td&gt;41&lt;/td&gt;
&lt;td&gt;13.31%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;I don’t know&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;1.62%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The results are rather quite self-explaining. Improved performance of Airflow, better
UI, and more telemetry are desirable. But this should go in pair with improved
documentation and resources about using the Airflow, especially when we
take into account the problem of onboarding new users.&lt;/p&gt;
&lt;p&gt;Another interesting point from that question is that only 16% think that operators
should be extended and improved. This suggests that we should focus on improving
Airflow core instead of adding more and more integrations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What would be the most interesting feature for you?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;No.&lt;/th&gt;
&lt;th&gt;%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Production-ready Airflow docker image&lt;/td&gt;
&lt;td&gt;175&lt;/td&gt;
&lt;td&gt;56.82%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Declarative way of writing DAGs / automated DAGs generation&lt;/td&gt;
&lt;td&gt;155&lt;/td&gt;
&lt;td&gt;50.32%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Horizontal Autoscaling&lt;/td&gt;
&lt;td&gt;122&lt;/td&gt;
&lt;td&gt;39.61%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Asynchronous Operators&lt;/td&gt;
&lt;td&gt;97&lt;/td&gt;
&lt;td&gt;31.49%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Stateless web server&lt;/td&gt;
&lt;td&gt;81&lt;/td&gt;
&lt;td&gt;26.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Knative Executor&lt;/td&gt;
&lt;td&gt;48&lt;/td&gt;
&lt;td&gt;15.58%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;I already have all I need&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;4.22%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Production Docker image wins, and it’s not a surprise. We all know that deploying
Airflow is not a plug and play process, and that’s why the official image is being
worked on by Jarek Potiuk. An unexpected result is that half of the users would like to
have a declarative way of creating DAGs. That seems to be something that is “against Airflow”
as we always emphasize the possibility of writing workflows in pure python. Stories
about DAG generators are not new and confirm that there’s a need for a way to
declare DAGs.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;If you think I missed something and you want to look for insights on your own the data is available
for you here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Original data: &lt;a href=&#34;https://storage.googleapis.com/airflow-survey/survey.csv&#34;&gt;https://storage.googleapis.com/airflow-survey/survey.csv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Processed: &lt;a href=&#34;https://storage.googleapis.com/airflow-survey/airflow_survey_processed.csv&#34;&gt;https://storage.googleapis.com/airflow-survey/airflow_survey_processed.csv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The processed data includes multi-choice options one-hot encoded. If you find any interesting
insight, please update the article (&lt;a href=&#34;https://github.com/apache/airflow-site/blob/aip-11/CONTRIBUTE.md&#34;&gt;make PR&lt;/a&gt;
to Airflow site).&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Blog: New Airflow website</title>
      <link>/blog/announcing-new-website/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/announcing-new-website/</guid>
      <description>
        
        
        &lt;p&gt;The brand &lt;a href=&#34;https://airflow.apache.org/&#34;&gt;new Airflow website&lt;/a&gt; has arrived! Those who have been following the process know that the journey to update &lt;a href=&#34;https://airflow.readthedocs.io/en/1.10.6/&#34;&gt;the old Airflow website&lt;/a&gt; started at the beginning of the year.
Thanks to sponsorship from the Cloud Composer team at Google that allowed us to
collaborate with &lt;a href=&#34;https://www.polidea.com/&#34;&gt;Polidea&lt;/a&gt; and with their design studio &lt;a href=&#34;https://utilodesign.com/&#34;&gt;Utilo&lt;/a&gt;, and deliver an awesome website.&lt;/p&gt;
&lt;p&gt;Documentation of open source projects is key to engaging new contributors in the maintenance,
development, and adoption of software. We want the Apache Airflow community to have
the best possible experience to contribute and use the project. We also took this opportunity to make the project
more accessible, and in doing so, increase its reach.&lt;/p&gt;
&lt;p&gt;In the past three and a half months, we have updated everything: created a more efficient landing page,
enhanced information architecture, and improved UX &amp;amp; UI. Most importantly, the website now has capabilities
to be translated into many languages. This is our effort to foster a more inclusive community around
Apache Airflow, and we look forward to seeing contributions in Spanish, Chinese, Russian, and other languages as well!&lt;/p&gt;
&lt;p&gt;We built our website on Docsy, a platform that is easy to use and contribute to. Follow
&lt;a href=&#34;https://github.com/apache/airflow-site/blob/aip-11/README.md&#34;&gt;these steps&lt;/a&gt; to set up your environment and
to create your first pull request. You may also use
the new website for your own open source project as a template.
All of our &lt;a href=&#34;https://github.com/apache/airflow-site/tree/aip-11&#34;&gt;code is open and hosted on Github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Share your questions, comments, and suggestions with us, to help us improve the website.
We hope that this new design makes finding documentation about Airflow easier,
and that its improved accessibility increases adoption and use of Apache Airflow around the world.&lt;/p&gt;
&lt;p&gt;Happy browsing!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Blog: ApacheCon Europe 2019 — Thoughts and Insights by Airflow Committers</title>
      <link>/blog/apache-con-europe-2019-thoughts-and-insights-by-airflow-committers/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/apache-con-europe-2019-thoughts-and-insights-by-airflow-committers/</guid>
      <description>
        
        
        &lt;p&gt;Is it possible to create an organization that delivers tens of projects used by millions, nearly no one is paid for doing their job, and still, it has been fruitfully carrying on for more than 20 years? Apache Software Foundation proves it is possible. For the last two decades, ASF has been crafting a model called the Apache Way—a way of organizing and leading tech open source projects. Due to this approach, which is strongly based on the “community over code” motto, we can enjoy such awesome projects like Apache Spark, Flink, Beam, or Airflow (and many more).&lt;/p&gt;
&lt;p&gt;After this year’s ApacheCon, Polidea’s engineers talked with Committers of Apache projects, such as—Aizhamal Nurmamat kyzy, Felix Uellendall, and Fokko Driesprong—about insights to what makes the ASF such an amazing organization.&lt;/p&gt;
&lt;p&gt;You can read the &lt;a href=&#34;https://www.polidea.com/blog/apachecon-europe-2019-thoughts-and-insights-by-airflow-committers/?utm_source=ApacheAirflowBlog&amp;amp;utm_medium=Npaid&amp;amp;utm_campaign=Blog&amp;amp;utm_term=Article&amp;amp;utm_content=AAB_NOP_BLG_ART_APC_001&#34;&gt;insights on the Polidea blog&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Blog: Documenting using local development environment</title>
      <link>/blog/documenting-using-local-development-environments/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/documenting-using-local-development-environments/</guid>
      <description>
        
        
        &lt;h2 id=&#34;documenting-local-development-environment-of-apache-airflow&#34;&gt;Documenting local development environment of Apache Airflow&lt;/h2&gt;
&lt;p&gt;From Sept to November, 2019 I have been participating in a wonderful initiative, &lt;a href=&#34;https://developers.google.com/season-of-docs&#34;&gt;Google Season of Docs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I had a pleasure to contribute to the Apache Airflow open source project as a technical writer.
My initial assignment was an extension to the github-based Contribution guide.&lt;/p&gt;
&lt;p&gt;From the very first days I have been pretty closely involved into inter-project communications
via emails/slack and had regular 1:1s with my mentor, Jarek Potiuk.&lt;/p&gt;
&lt;p&gt;I got infected with Jarek’s enthusiasm to ease the on-boarding experience for
Airflow contributors. I do share this strategy and did my best to improve the structure,
language and DX. As a result, Jarek and I extended the current contributor’s docs and
ended up with the Contributing guide navigating the users through the project
infrastructure and providing a workflow example based on a real-life use case;
the Testing guide with an overview of a complex testing infrastructure for Apache Airflow;
and two guides dedicated to the Breeze dev environment and local virtual environment
(my initial assignment).&lt;/p&gt;
&lt;p&gt;I’m deeply grateful to my mentor and Airflow developers for their feedback,
patience and help while I was breaking through new challenges
(I’ve never worked on an open source project before),
and for their support of all my ideas! I think a key success factor for any contributor
is a responsive, supportive and motivated team, and I was lucky to join such
a team for 3 months.&lt;/p&gt;
&lt;p&gt;Documents I worked on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/airflow/blob/master/BREEZE.rst&#34;&gt;Breeze development environment documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/airflow/blob/master/LOCAL_VIRTUALENV.rst&#34;&gt;Local virtualenv environment documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/airflow/blob/master/CONTRIBUTING.rst&#34;&gt;Contributing guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/airflow/blob/master/TESTING.rst&#34;&gt;Testing guide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Blog: It&#39;s a &#34;Breeze&#34; to develop Apache Airflow</title>
      <link>/blog/its-a-breeze-to-develop-apache-airflow/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/its-a-breeze-to-develop-apache-airflow/</guid>
      <description>
        
        
        &lt;h2 id=&#34;the-story-behind-the-airflow-breeze-tool&#34;&gt;The story behind the Airflow Breeze tool&lt;/h2&gt;
&lt;p&gt;Initially, we started contributing to this fantastic open-source project [Apache Airflow] with a team of three which then grew to five. When we kicked it off a year ago, I realized pretty soon where the biggest bottlenecks and areas for improvement in terms of productivity were. Even with the help of our client, who provided us with a “homegrown” development environment it took us literally days to set it up and learn some basics.&lt;/p&gt;
&lt;p&gt;That is how the journey to increased productivity in Apache Airflow began. The result? The Airflow Breeze open-source tool. Jarek Potiuk, an Airflow Committer, will tell you all about it.&lt;/p&gt;
&lt;p&gt;You can learn &lt;a href=&#34;https://www.polidea.com/blog/its-a-breeze-to-develop-apache-airflow/?utm_source=ApacheAirflowBlog&amp;amp;utm_medium=Npaid&amp;amp;utm_campaign=Blog&amp;amp;utm_term=Article&amp;amp;utm_content=AAB_NOP_BLG_ART_AB_001&#34;&gt;how and why it’s a &amp;ldquo;Breeze&amp;rdquo; to Develop Apache Airflow on Polidea blog&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
